# API endpoint
https://gww8r73ofa.execute-api.us-east-1.amazonaws.com/Prod/trigger-preprocess

# API Gateway input json
{
  "folders": ["2024-01", "2024-02"],
  "speed_tag": ["DWA", "DWB"]
}


# CLI
curl -X POST https://gww8r73ofa.execute-api.us-east-1.amazonaws.com/Prod/trigger-preprocess \
  -H "Content-Type: application/json" \
  --data-binary @inputs/01_pipeline_input.json

# CLI 2
curl -X POST https://gww8r73ofa.execute-api.us-east-1.amazonaws.com/Prod/trigger-preprocess \
  -H "Content-Type: application/json" \
  -d '{"folders": ["2024-01", "2024-02"]}'


# upload manually
aws s3 sync pipelines/02_training_kmeans/ s3://swo-ngoctran-public/mlops/jobs/02_training_kmeans/pipelines/02_training_kmeans/

# see how many MB of dependencies
du -sh .aws-sam



# upload all .py manually
#!/bin/bash

# === CONFIG ===
S3_BUCKET="s3-assetcare-bucket"
BASE_PREFIX="mlops/jobs"

# === Upload táº¥t cáº£ folder trong pipelines/ ===
for folder in pipelines/*/; do
  job_name=$(basename "$folder")
  echo "ðŸ“¤ Syncing $folder to s3://$S3_BUCKET/$BASE_PREFIX/$job_name/"
  aws s3 sync "$folder" "s3://$S3_BUCKET/$BASE_PREFIX/$job_name/" --exclude "*" --include "*.py"
done

# === Upload cÃ¡c file .py trong shared/ (náº¿u cÃ³) ===
if [ -d "shared" ]; then
  echo "ðŸ“¤ Syncing shared/ to s3://$S3_BUCKET/$BASE_PREFIX/shared/"
  aws s3 sync shared/ "s3://$S3_BUCKET/$BASE_PREFIX/shared/" --exclude "*" --include "*.py"
fi

echo "âœ… Done uploading updated .py files to S3"
